{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFxLD4Zb4gws",
        "outputId": "927a0f30-42a8-4f04-9688-4d0ee2ee2320"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, radius_graph\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "Dxh8gjJw4VK1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCwDO-i_4WPv",
        "outputId": "314479ae-3aa9-48aa-e49e-c4313ce4320a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/My Drive/datasets_itmo/stadium_main_300\""
      ],
      "metadata": {
        "id": "4-uumC8M4mDG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PKjN_WnX4NMK"
      },
      "outputs": [],
      "source": [
        "#os.makedirs('train_log', exist_ok=True)\n",
        "#os.makedirs('rollouts', exist_ok=True)\n",
        "INPUT_SEQUENCE_LENGTH = 6\n",
        "batch_size = 2\n",
        "noise_std = 6.7e-4\n",
        "training_steps = int(2e7)\n",
        "log_steps = 5\n",
        "eval_steps = 20\n",
        "save_steps = 100\n",
        "model_path = None # 'model425000.pth'\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждый .pickle файл соответствует одному видео и содержит список списков с результатами покадрового распознавания в формате [robot_id (int), orientation_degree (float), position (tuple)].\n",
        "\n",
        "Дополнительная ремарка относительно названий файлов: первое число — секунда старта трекинга, второе — секунда завершения, третье — количество роботов, число после флага PWM — интенсивность вибрации (= степень подвижности), зафиксированная для всех роботов в рамках одного видео."
      ],
      "metadata": {
        "id": "8x7GRIM-72Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path+'/00_62_[45_bots_PWM_2_ex_153].pickle', 'rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "metadata": {
        "id": "wvB9DV0b6SR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdNqoUXp6coR",
        "outputId": "995e1122-337e-418d-d183-bcca43462a50"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 336.8014094863518, (1052, 450)],\n",
              " [4, 75.96375653207353, (1053, 583)],\n",
              " [5, 302.7352262721076, (1046, 742)],\n",
              " [7, 75.96375653207353, (1090, 368)],\n",
              " [9, 154.9831065219, (725, 475)],\n",
              " [12, 209.74488129694222, (1184, 200)],\n",
              " [13, 284.93141717813756, (905, 471)],\n",
              " [20, 172.8749836510982, (1221, 646)],\n",
              " [22, 342.64597536373867, (1284, 245)],\n",
              " [25, 154.9831065219, (1124, 693)],\n",
              " [26, 68.19859051364818, (1296, 498)],\n",
              " [27, 75.96375653207353, (880, 311)],\n",
              " [28, 115.01689347810004, (1097, 775)],\n",
              " [30, 3.3664606634298013, (1234, 310)],\n",
              " [31, 10.619655276155134, (960, 580)],\n",
              " [32, 291.8014094863518, (852, 436)],\n",
              " [39, 52.43140797117251, (1266, 403)],\n",
              " [41, 6.7098368077569335, (1388, 579)],\n",
              " [46, 266.4236656250026, (900, 650)],\n",
              " [47, 333.434948822922, (1090, 498)],\n",
              " [50, 232.43140797117252, (999, 256)],\n",
              " [51, 86.42366562500266, (1225, 470)],\n",
              " [52, 176.42366562500266, (925, 186)],\n",
              " [54, 334.98310652189997, (936, 372)],\n",
              " [55, 25.016893478100023, (1036, 656)],\n",
              " [56, 76.7594800848128, (826, 332)],\n",
              " [57, 97.1250163489018, (1195, 562)],\n",
              " [58, 64.98310652189998, (777, 380)],\n",
              " [59, 93.3664606634298, (1252, 565)],\n",
              " [60, 201.80140948635182, (776, 600)],\n",
              " [62, 240.25511870305778, (1025, 368)],\n",
              " [65, 82.8749836510982, (959, 662)],\n",
              " [66, 251.56505117707798, (1162, 464)],\n",
              " [68, 37.568592028827496, (1233, 720)],\n",
              " [69, 129.8055710922652, (1124, 557)],\n",
              " [70, 356.6335393365702, (1360, 400)],\n",
              " [72, 3.576334374997351, (1367, 460)],\n",
              " [74, 161.565051177078, (1128, 629)],\n",
              " [76, 6.7098368077569335, (1390, 520)],\n",
              " [77, 333.434948822922, (1176, 375)],\n",
              " [78, 214.69515353123396, (953, 745)],\n",
              " [79, 345.96375653207355, (1309, 681)],\n",
              " [81, 72.64597536373867, (1169, 764)],\n",
              " [82, 42.510447078000844, (1116, 225)],\n",
              " [83, 64.98310652189998, (933, 269)]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "метаданные оригинала\n",
        "\n",
        "Metadata file with dataset information (sequence length, dimensionality, box bounds, default connectivity radius, statistics for normalization, ...):"
      ],
      "metadata": {
        "id": "VMqbvDe69_VY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проблема - заменить в коде данные из оригинальных метаданных на наши данные**"
      ],
      "metadata": {
        "id": "6hXqjGxe-P-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('data/metadata.json', 'rt') as f:\n",
        "\n",
        "#num_steps = metadata['sequence_length'] - INPUT_SEQUENCE_LENGTH\n",
        "num_steps = len(data) # попробуем сделать от количества кадров\n",
        "normalization_stats = {\n",
        "    'acceleration': {\n",
        "        'mean':torch.FloatTensor(metadata['acc_mean']).to(device),\n",
        "        'std':torch.sqrt(torch.FloatTensor(metadata['acc_std'])**2 + noise_std**2).to(device),\n",
        "    },\n",
        "    'velocity': {\n",
        "        'mean':torch.FloatTensor(metadata['vel_mean']).to(device),\n",
        "        'std':torch.sqrt(torch.FloatTensor(metadata['vel_std'])**2 + noise_std**2).to(device),\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "BlJmo4AM4Tdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(\n",
        "    input_size,\n",
        "    layer_sizes,\n",
        "    output_size=None,\n",
        "    output_activation=torch.nn.Identity,\n",
        "    activation=torch.nn.ReLU,\n",
        "):\n",
        "    sizes = [input_size] + layer_sizes\n",
        "    if output_size:\n",
        "        sizes.append(output_size)\n",
        "\n",
        "    layers = []\n",
        "    for i in range(len(sizes) - 1):\n",
        "        act = activation if i < len(sizes) - 2 else output_activation\n",
        "        layers += [torch.nn.Linear(sizes[i], sizes[i + 1]), act()]\n",
        "    return torch.nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "gZH0Tu1T5IXo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_diff(input_sequence):\n",
        "    return input_sequence[:, 1:] - input_sequence[:, :-1]"
      ],
      "metadata": {
        "id": "SYITMrIq9BOp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_walk_noise_for_position_sequence(position_sequence, noise_std_last_step):\n",
        "    \"\"\"Returns random-walk noise in the velocity applied to the position.\"\"\"\n",
        "    velocity_sequence = time_diff(position_sequence)\n",
        "    num_velocities = velocity_sequence.shape[1]\n",
        "    velocity_sequence_noise = torch.randn(list(velocity_sequence.shape)) * (noise_std_last_step/num_velocities**0.5)\n",
        "\n",
        "    velocity_sequence_noise = torch.cumsum(velocity_sequence_noise, dim=1)\n",
        "\n",
        "    position_sequence_noise = torch.cat([\n",
        "        torch.zeros_like(velocity_sequence_noise[:, 0:1]),\n",
        "        torch.cumsum(velocity_sequence_noise, dim=1)], dim=1)\n",
        "\n",
        "    return position_sequence_noise"
      ],
      "metadata": {
        "id": "DU2vH8JG9C_O"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _read_metadata(data_path):\n",
        "    with open(os.path.join(data_path, 'metadata.json'), 'rt') as fp:\n",
        "        return json.loads(fp.read())"
      ],
      "metadata": {
        "id": "UHG3qSxP9Edn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.node_fn = nn.Sequential(*[build_mlp(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "            nn.LayerNorm(node_out)])\n",
        "        self.edge_fn = nn.Sequential(*[build_mlp(edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "            nn.LayerNorm(edge_out)])\n",
        "\n",
        "    def forward(self, x, edge_index, e_features): # global_features\n",
        "        # x: (E, node_in)\n",
        "        # edge_index: (2, E)\n",
        "        # e_features: (E, edge_in)\n",
        "        return self.node_fn(x), self.edge_fn(e_features)"
      ],
      "metadata": {
        "id": "tzmjXO0J9F7F"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionNetwork(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(InteractionNetwork, self).__init__(aggr='add')\n",
        "        self.node_fn = nn.Sequential(*[build_mlp(node_in+edge_out, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out),\n",
        "            nn.LayerNorm(node_out)])\n",
        "        self.edge_fn = nn.Sequential(*[build_mlp(node_in+node_in+edge_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], edge_out),\n",
        "            nn.LayerNorm(edge_out)])\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        # x: (E, node_in)\n",
        "        # edge_index: (2, E)\n",
        "        # e_features: (E, edge_in)\n",
        "        x_residual = x\n",
        "        e_features_residual = e_features\n",
        "        x, e_features = self.propagate(edge_index=edge_index, x=x, e_features=e_features)\n",
        "        return x+x_residual, e_features+e_features_residual\n",
        "\n",
        "    def message(self, edge_index, x_i, x_j, e_features):\n",
        "        e_features = torch.cat([x_i, x_j, e_features], dim=-1)\n",
        "        e_features = self.edge_fn(e_features)\n",
        "        return e_features\n",
        "\n",
        "    def update(self, x_updated, x, e_features):\n",
        "        # x_updated: (E, edge_out)\n",
        "        # x: (E, node_in)\n",
        "        x_updated = torch.cat([x_updated, x], dim=-1)\n",
        "        x_updated = self.node_fn(x_updated)\n",
        "        return x_updated, e_features"
      ],
      "metadata": {
        "id": "h4TXYWN09Hop"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Processor(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        edge_out,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Processor, self).__init__(aggr='max')\n",
        "        self.gnn_stacks = nn.ModuleList([\n",
        "            InteractionNetwork(\n",
        "                node_in=node_in,\n",
        "                node_out=node_out,\n",
        "                edge_in=edge_in,\n",
        "                edge_out=edge_out,\n",
        "                mlp_num_layers=mlp_num_layers,\n",
        "                mlp_hidden_dim=mlp_hidden_dim,\n",
        "            ) for _ in range(num_message_passing_steps)])\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        for gnn in self.gnn_stacks:\n",
        "            x, e_features = gnn(x, edge_index, e_features)\n",
        "        return x, e_features"
      ],
      "metadata": {
        "id": "rJO2AJKj9KbK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.node_fn = build_mlp(node_in, [mlp_hidden_dim for _ in range(mlp_num_layers)], node_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (E, node_in)\n",
        "        return self.node_fn(x)"
      ],
      "metadata": {
        "id": "vsibg3z19L9x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodeProcessDecode(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_in,\n",
        "        node_out,\n",
        "        edge_in,\n",
        "        latent_dim,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "    ):\n",
        "        super(EncodeProcessDecode, self).__init__()\n",
        "        self._encoder = Encoder(\n",
        "            node_in=node_in,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=edge_in,\n",
        "            edge_out=latent_dim,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "        self._processor = Processor(\n",
        "            node_in=latent_dim,\n",
        "            node_out=latent_dim,\n",
        "            edge_in=latent_dim,\n",
        "            edge_out=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "        self._decoder = Decoder(\n",
        "            node_in=latent_dim,\n",
        "            node_out=node_out,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, e_features):\n",
        "        # x: (E, node_in)\n",
        "        x, e_features = self._encoder(x, edge_index, e_features)\n",
        "        x, e_features = self._processor(x, edge_index, e_features)\n",
        "        x = self._decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "laYbko829NZh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        particle_dimension,\n",
        "        node_in,\n",
        "        edge_in,\n",
        "        latent_dim,\n",
        "        num_message_passing_steps,\n",
        "        mlp_num_layers,\n",
        "        mlp_hidden_dim,\n",
        "        connectivity_radius,\n",
        "        boundaries,\n",
        "        normalization_stats,\n",
        "        num_particle_types,\n",
        "        particle_type_embedding_size,\n",
        "        device='cuda',\n",
        "    ):\n",
        "        super(Simulator, self).__init__()\n",
        "        self._boundaries = boundaries\n",
        "        self._connectivity_radius = connectivity_radius\n",
        "        self._normalization_stats = normalization_stats\n",
        "        self._num_particle_types = num_particle_types\n",
        "\n",
        "        self._particle_type_embedding = nn.Embedding(num_particle_types, particle_type_embedding_size) # (9, 16)\n",
        "\n",
        "        self._encode_process_decode = EncodeProcessDecode(\n",
        "            node_in=node_in,\n",
        "            node_out=particle_dimension,\n",
        "            edge_in=edge_in,\n",
        "            latent_dim=latent_dim,\n",
        "            num_message_passing_steps=num_message_passing_steps,\n",
        "            mlp_num_layers=mlp_num_layers,\n",
        "            mlp_hidden_dim=mlp_hidden_dim,\n",
        "        )\n",
        "\n",
        "        self._device = device\n",
        "\n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def _build_graph_from_raw(self, position_sequence, n_particles_per_example, particle_types):\n",
        "        n_total_points = position_sequence.shape[0]\n",
        "        most_recent_position = position_sequence[:, -1] # (n_nodes, 2)\n",
        "        velocity_sequence = time_diff(position_sequence)\n",
        "        # senders and receivers are integers of shape (E,)\n",
        "        senders, receivers = self._compute_connectivity(most_recent_position, n_particles_per_example, self._connectivity_radius)\n",
        "        node_features = []\n",
        "        # Normalized velocity sequence, merging spatial an time axis.\n",
        "        velocity_stats = self._normalization_stats[\"velocity\"]\n",
        "        normalized_velocity_sequence = (velocity_sequence - velocity_stats['mean']) / velocity_stats['std']\n",
        "        flat_velocity_sequence = normalized_velocity_sequence.view(n_total_points, -1)\n",
        "        node_features.append(flat_velocity_sequence)\n",
        "\n",
        "        # Normalized clipped distances to lower and upper boundaries.\n",
        "        # boundaries are an array of shape [num_dimensions, 2], where the second\n",
        "        # axis, provides the lower/upper boundaries.\n",
        "        boundaries = torch.tensor(self._boundaries, requires_grad=False).float().to(self._device)\n",
        "        distance_to_lower_boundary = (most_recent_position - boundaries[:, 0][None])\n",
        "        distance_to_upper_boundary = (boundaries[:, 1][None] - most_recent_position)\n",
        "        distance_to_boundaries = torch.cat([distance_to_lower_boundary, distance_to_upper_boundary], dim=1)\n",
        "        normalized_clipped_distance_to_boundaries = torch.clamp(distance_to_boundaries / self._connectivity_radius, -1., 1.)\n",
        "        node_features.append(normalized_clipped_distance_to_boundaries)\n",
        "\n",
        "        if self._num_particle_types > 1:\n",
        "            particle_type_embeddings = self._particle_type_embedding(particle_types)\n",
        "            node_features.append(particle_type_embeddings)\n",
        "\n",
        "        # Collect edge features.\n",
        "        edge_features = []\n",
        "\n",
        "        # Relative displacement and distances normalized to radius\n",
        "        # (E, 2)\n",
        "        # normalized_relative_displacements = (\n",
        "        #     torch.gather(most_recent_position, 0, senders) - torch.gather(most_recent_position, 0, receivers)\n",
        "        # ) / self._connectivity_radius\n",
        "        normalized_relative_displacements = (\n",
        "            most_recent_position[senders, :] - most_recent_position[receivers, :]\n",
        "        ) / self._connectivity_radius\n",
        "        edge_features.append(normalized_relative_displacements)\n",
        "\n",
        "        normalized_relative_distances = torch.norm(normalized_relative_displacements, dim=-1, keepdim=True)\n",
        "        edge_features.append(normalized_relative_distances)\n",
        "\n",
        "        return torch.cat(node_features, dim=-1), torch.stack([senders, receivers]), torch.cat(edge_features, dim=-1)\n",
        "\n",
        "    def _compute_connectivity(self, node_features, n_particles_per_example, radius, add_self_edges=True):\n",
        "        # handle batches. Default is 2 examples per batch\n",
        "\n",
        "        # Specify examples id for particles/points\n",
        "        batch_ids = torch.cat([torch.LongTensor([i for _ in range(n)]) for i, n in enumerate(n_particles_per_example)]).to(self._device)\n",
        "        # radius = radius + 0.00001 # radius_graph takes r < radius not r <= radius\n",
        "        edge_index = radius_graph(node_features, r=radius, batch=batch_ids, loop=add_self_edges) # (2, n_edges)\n",
        "        receivers = edge_index[0, :]\n",
        "        senders = edge_index[1, :]\n",
        "        return receivers, senders\n",
        "\n",
        "    def _decoder_postprocessor(self, normalized_acceleration, position_sequence):\n",
        "        # The model produces the output in normalized space so we apply inverse\n",
        "        # normalization.\n",
        "        acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "        acceleration = (\n",
        "            normalized_acceleration * acceleration_stats['std']\n",
        "        ) + acceleration_stats['mean']\n",
        "\n",
        "        # Use an Euler integrator to go from acceleration to position, assuming\n",
        "        # a dt=1 corresponding to the size of the finite difference.\n",
        "        most_recent_position = position_sequence[:, -1]\n",
        "        most_recent_velocity = most_recent_position - position_sequence[:, -2]\n",
        "\n",
        "        new_velocity = most_recent_velocity + acceleration  # * dt = 1\n",
        "        new_position = most_recent_position + new_velocity  # * dt = 1\n",
        "        return new_position\n",
        "\n",
        "    def predict_positions(self, current_positions, n_particles_per_example, particle_types):\n",
        "        node_features, edge_index, e_features = self._build_graph_from_raw(current_positions, n_particles_per_example, particle_types)\n",
        "        predicted_normalized_acceleration = self._encode_process_decode(node_features, edge_index, e_features)\n",
        "        next_position = self._decoder_postprocessor(predicted_normalized_acceleration, current_positions)\n",
        "        return next_position\n",
        "\n",
        "    def predict_accelerations(self, next_position, position_sequence_noise, position_sequence, n_particles_per_example, particle_types):\n",
        "        noisy_position_sequence = position_sequence + position_sequence_noise\n",
        "        node_features, edge_index, e_features = self._build_graph_from_raw(noisy_position_sequence, n_particles_per_example, particle_types)\n",
        "        predicted_normalized_acceleration = self._encode_process_decode(node_features, edge_index, e_features)\n",
        "        next_position_adjusted = next_position + position_sequence_noise[:, -1]\n",
        "        target_normalized_acceleration = self._inverse_decoder_postprocessor(next_position_adjusted, noisy_position_sequence)\n",
        "        return predicted_normalized_acceleration, target_normalized_acceleration\n",
        "\n",
        "    def _inverse_decoder_postprocessor(self, next_position, position_sequence):\n",
        "        \"\"\"Inverse of `_decoder_postprocessor`.\"\"\"\n",
        "        previous_position = position_sequence[:, -1]\n",
        "        previous_velocity = previous_position - position_sequence[:, -2]\n",
        "        next_velocity = next_position - previous_position\n",
        "        acceleration = next_velocity - previous_velocity\n",
        "\n",
        "        acceleration_stats = self._normalization_stats[\"acceleration\"]\n",
        "        normalized_acceleration = (acceleration - acceleration_stats['mean']) / acceleration_stats['std']\n",
        "        return normalized_acceleration\n",
        "\n",
        "    def save(self, path='model.pth'):\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "zAwgGEWo9O9n"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_from_tfds(data_path='data/train.tfrecord', is_rollout=False, batch_size=2):\n",
        "    import functools\n",
        "    import tensorflow.compat.v1 as tf\n",
        "    import tensorflow_datasets as tfds\n",
        "    import reading_utils\n",
        "    import tree\n",
        "    from tfrecord.torch.dataset import TFRecordDataset\n",
        "    def prepare_inputs(tensor_dict):\n",
        "        pos = tensor_dict['position']\n",
        "        pos = tf.transpose(pos, perm=[1, 0, 2])\n",
        "        target_position = pos[:, -1]\n",
        "        tensor_dict['position'] = pos[:, :-1]\n",
        "        num_particles = tf.shape(pos)[0]\n",
        "        tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
        "        if 'step_context' in tensor_dict:\n",
        "            tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
        "            tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
        "        return tensor_dict, target_position\n",
        "    def batch_concat(dataset, batch_size):\n",
        "        windowed_ds = dataset.window(batch_size)\n",
        "        initial_state = tree.map_structure(lambda spec: tf.zeros(shape=[0] + spec.shape.as_list()[1:], dtype=spec.dtype),dataset.element_spec)\n",
        "        def reduce_window(initial_state, ds):\n",
        "            return ds.reduce(initial_state, lambda x, y: tf.concat([x, y], axis=0))\n",
        "        return windowed_ds.map(lambda *x: tree.map_structure(reduce_window, initial_state, x))\n",
        "    def prepare_rollout_inputs(context, features):\n",
        "        out_dict = {**context}\n",
        "        pos = tf.transpose(features['position'], [1, 0, 2])\n",
        "        target_position = pos[:, -1]\n",
        "        out_dict['position'] = pos[:, :-1]\n",
        "        out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
        "        if 'step_context' in features:\n",
        "            out_dict['step_context'] = features['step_context']\n",
        "        out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
        "        return out_dict, target_position\n",
        "\n",
        "    metadata = _read_metadata('data/')\n",
        "    ds = tf.data.TFRecordDataset([data_path])\n",
        "    ds = ds.map(functools.partial(reading_utils.parse_serialized_simulation_example, metadata=metadata))\n",
        "    if is_rollout:\n",
        "        ds = ds.map(prepare_rollout_inputs)\n",
        "    else:\n",
        "        split_with_window = functools.partial(\n",
        "            reading_utils.split_trajectory,\n",
        "            window_length=6 + 1)\n",
        "        ds = ds.flat_map(split_with_window)\n",
        "        ds = ds.map(prepare_inputs)\n",
        "        ds = ds.repeat()\n",
        "        ds = ds.shuffle(512)\n",
        "        ds = batch_concat(ds, batch_size)\n",
        "    ds = tfds.as_numpy(ds)\n",
        "    for i in range(100): # clear screen\n",
        "        print()\n",
        "    return ds"
      ],
      "metadata": {
        "id": "nwanE8xb9RzP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_single_rollout(simulator, features, num_steps, device):\n",
        "    initial_positions = features['position'][:, 0:INPUT_SEQUENCE_LENGTH]\n",
        "    ground_truth_positions = features['position'][:, INPUT_SEQUENCE_LENGTH:]\n",
        "\n",
        "    current_positions = initial_positions\n",
        "    predictions = []\n",
        "    for step in range(num_steps):\n",
        "        next_position = simulator.predict_positions(\n",
        "            current_positions,\n",
        "            n_particles_per_example=features['n_particles_per_example'],\n",
        "            particle_types=features['particle_type'],\n",
        "        ) # (n_nodes, 2)\n",
        "        # Update kinematic particles from prescribed trajectory.\n",
        "        kinematic_mask = (features['particle_type'] == 3).clone().detach().to(device)\n",
        "        next_position_ground_truth = ground_truth_positions[:, step]\n",
        "        kinematic_mask = kinematic_mask.bool()[:, None].expand(-1, 2)\n",
        "        next_position = torch.where(kinematic_mask, next_position_ground_truth, next_position)\n",
        "        predictions.append(next_position)\n",
        "        current_positions = torch.cat([current_positions[:, 1:], next_position[:, None, :]], dim=1)\n",
        "    predictions = torch.stack(predictions) # (time, n_nodes, 2)\n",
        "    ground_truth_positions = ground_truth_positions.permute(1,0,2)\n",
        "    loss = (predictions - ground_truth_positions) ** 2\n",
        "    output_dict = {\n",
        "        'initial_positions': initial_positions.permute(1,0,2).cpu().numpy(),\n",
        "        'predicted_rollout': predictions.cpu().numpy(),\n",
        "        'ground_truth_rollout': ground_truth_positions.cpu().numpy(),\n",
        "        'particle_types': features['particle_type'].cpu().numpy(),\n",
        "    }\n",
        "    return output_dict, loss"
      ],
      "metadata": {
        "id": "HijTPpD09Tpz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_rollout(ds, simulator, num_steps, num_eval_steps=1, save_results=False, device='cuda'):\n",
        "    eval_loss = []\n",
        "    i = 0\n",
        "    simulator.eval()\n",
        "    with torch.no_grad():\n",
        "        for example_i, (features, labels) in enumerate(ds):\n",
        "            features['position'] = torch.tensor(features['position']).to(device) # (n_nodes, 600, 2)\n",
        "            features['n_particles_per_example'] = torch.tensor(features['n_particles_per_example']).to(device)\n",
        "            features['particle_type'] = torch.tensor(features['particle_type']).to(device)\n",
        "            labels = torch.tensor(labels).to(device)\n",
        "            example_rollout, loss = eval_single_rollout(simulator, features, num_steps, device)\n",
        "            example_rollout['metadata'] = metadata\n",
        "            eval_loss.append(loss)\n",
        "            if save_results:\n",
        "                example_rollout['metadata'] = metadata\n",
        "                filename = f'rollout_{example_i}.pkl'\n",
        "                filename = os.path.join('rollouts/', filename)\n",
        "                with open(filename, 'wb') as f:\n",
        "                    pickle.dump(example_rollout, f)\n",
        "            i += 1\n",
        "            if i >= num_eval_steps:\n",
        "                break\n",
        "    simulator.train()\n",
        "    return torch.stack(eval_loss).mean(0)"
      ],
      "metadata": {
        "id": "dRS8rxKn9VOB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(simulator):\n",
        "    i = 0\n",
        "    while os.path.isdir('train_log/run'+str(i)):\n",
        "        i += 1\n",
        "    LOG_DIR = 'train_log/run'+str(i)+'/'\n",
        "\n",
        "    writer = SummaryWriter(LOG_DIR)\n",
        "\n",
        "    lr_init = 1e-4\n",
        "    lr_min = 1e-6\n",
        "    lr_decay = 0.1\n",
        "    lr_decay_steps = int(5e6)\n",
        "    lr_new = lr_init\n",
        "    optimizer = torch.optim.Adam(simulator.parameters(), lr=lr_init)\n",
        "\n",
        "    ds = prepare_data_from_tfds(batch_size=batch_size)\n",
        "    # ds_eval = prepare_data_from_tfds(data_path='data/valid.tfrecord', is_rollout=True)\n",
        "\n",
        "    step = 0\n",
        "    try:\n",
        "        for features, labels in ds:\n",
        "            features['position'] = torch.tensor(features['position']).to(device)\n",
        "            features['n_particles_per_example'] = torch.tensor(features['n_particles_per_example']).to(device)\n",
        "            features['particle_type'] = torch.tensor(features['particle_type']).to(device)\n",
        "            labels = torch.tensor(labels).to(device)\n",
        "\n",
        "            sampled_noise = get_random_walk_noise_for_position_sequence(features['position'], noise_std_last_step=noise_std).to(device)\n",
        "            non_kinematic_mask = (features['particle_type'] != 3).clone().detach().to(device)\n",
        "            sampled_noise *= non_kinematic_mask.view(-1, 1, 1)\n",
        "\n",
        "            pred, target = simulator.predict_accelerations(\n",
        "                next_position=labels,\n",
        "                position_sequence_noise=sampled_noise,\n",
        "                position_sequence=features['position'],\n",
        "                n_particles_per_example=features['n_particles_per_example'],\n",
        "                particle_types=features['particle_type'],\n",
        "            )\n",
        "            loss = (pred - target) ** 2\n",
        "            loss = loss.sum(dim=-1)\n",
        "            num_non_kinematic = non_kinematic_mask.sum()\n",
        "\n",
        "            loss = torch.where(non_kinematic_mask.bool(), loss, torch.zeros_like(loss))\n",
        "            loss = loss.sum() / num_non_kinematic\n",
        "\n",
        "            if step % log_steps == 0:\n",
        "                writer.add_scalar(\"training_loss\", loss, step)\n",
        "                writer.add_scalar(\"lr\", lr_new, step)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            lr_new = lr_init * (lr_decay ** (step/lr_decay_steps))\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = lr_new\n",
        "\n",
        "            step += 1\n",
        "            print(f'Training step: {step}/{training_steps}. Loss: {loss}.', end=\"\\r\",)\n",
        "            if step >= training_steps == 0:\n",
        "                break\n",
        "\n",
        "            # if step % eval_steps == 0:\n",
        "            #     eval_loss = eval_rollout(ds_eval, simulator, num_steps, num_eval_steps=10, device=device)\n",
        "            #     writer.add_scalar(\"eval_loss\", eval_loss, step)\n",
        "\n",
        "            if step % save_steps == 0:\n",
        "                simulator.save(LOG_DIR+'model.pth')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    simulator.save(LOG_DIR+'model.pth')"
      ],
      "metadata": {
        "id": "MjTnd9_P9W8g"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(simulator):\n",
        "    ds = prepare_data_from_tfds(data_path='data/valid.tfrecord', is_rollout=True)\n",
        "    eval_rollout(ds, simulator, num_steps=num_steps, save_results=True, device=device)"
      ],
      "metadata": {
        "id": "QvwabHW-9Y_6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    simulator = Simulator(\n",
        "        particle_dimension=2,\n",
        "        node_in=30,\n",
        "        edge_in=3,\n",
        "        latent_dim=128,\n",
        "        num_message_passing_steps=10,\n",
        "        mlp_num_layers=2,\n",
        "        mlp_hidden_dim=128,\n",
        "        connectivity_radius=metadata['default_connectivity_radius'],\n",
        "        boundaries=np.array(metadata['bounds']),\n",
        "        normalization_stats=normalization_stats,\n",
        "        num_particle_types=9,\n",
        "        particle_type_embedding_size=16,\n",
        "        device=device,\n",
        "    )\n",
        "    if model_path is not None:\n",
        "        simulator.load(model_path)\n",
        "    if device == 'cuda':\n",
        "        simulator.cuda()\n",
        "    train(simulator)\n",
        "    # infer(simulator)"
      ],
      "metadata": {
        "id": "zRuMlQVk9a-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}